#!/usr/bin/env python3
"""
ToolACE æ•°æ®ç”Ÿæˆä¸»è„šæœ¬

è¯¥è„šæœ¬æ‰§è¡Œå®Œæ•´çš„ToolACEæ•°æ®ç”Ÿæˆç®¡é“ï¼ŒåŒ…æ‹¬:
1. Tool Self-Evolution Synthesis (TSS) - APIç”Ÿæˆ
2. Self-Guided Dialog Generation (SDG) - å¯¹è¯ç”Ÿæˆ  
3. Dual-Layer Verification (DLV) - è´¨é‡éªŒè¯
"""

import argparse
import os
import sys
import time
import yaml
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from toolace import ToolACE, initialize_global_model_manager
from toolace.utils.logger import setup_logger


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="ToolACE æ•°æ®ç”Ÿæˆç®¡é“")
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument(
        "--config", 
        type=str, 
        default="config/data_config.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    
    parser.add_argument(
        "--api_count",
        type=int,
        default=26507,
        help="ç›®æ ‡APIç”Ÿæˆæ•°é‡"
    )
    
    parser.add_argument(
        "--dialog_count", 
        type=int,
        default=100000,
        help="ç›®æ ‡å¯¹è¯ç”Ÿæˆæ•°é‡"
    )
    
    parser.add_argument(
        "--output_dir",
        type=str,
        default="data/generated/",
        help="è¾“å‡ºç›®å½•è·¯å¾„"
    )
    
    # æ¨¡å¼æ§åˆ¶
    parser.add_argument(
        "--tss_only",
        action="store_true",
        help="ä»…è¿è¡ŒTSSæ¨¡å—"
    )
    
    parser.add_argument(
        "--sdg_only", 
        action="store_true",
        help="ä»…è¿è¡ŒSDGæ¨¡å—"
    )
    
    parser.add_argument(
        "--dlv_only",
        action="store_true", 
        help="ä»…è¿è¡ŒDLVæ¨¡å—"
    )
    
    parser.add_argument(
        "--verify_only",
        action="store_true",
        help="ä»…éªŒè¯å·²ç”Ÿæˆçš„æ•°æ®"
    )
    
    # è°ƒè¯•å‚æ•°
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="è¯¦ç»†è¾“å‡ºæ¨¡å¼"
    )
    
    parser.add_argument(
        "--debug",
        action="store_true", 
        help="è°ƒè¯•æ¨¡å¼"
    )
    
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="éšæœºç§å­"
    )
    
    # æ€§èƒ½å‚æ•°
    parser.add_argument(
        "--num_workers",
        type=int,
        default=4,
        help="å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°"
    )
    
    parser.add_argument(
        "--batch_size",
        type=int, 
        default=32,
        help="æ‰¹å¤„ç†å¤§å°"
    )
    
    # æ¢å¤å‚æ•°
    parser.add_argument(
        "--resume_from",
        type=str,
        help="ä»æ£€æŸ¥ç‚¹æ¢å¤ç”Ÿæˆ"
    )
    
    return parser.parse_args()


def load_config(config_path: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        return config
    except FileNotFoundError:
        print(f"âŒ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
        sys.exit(1)
    except yaml.YAMLError as e:
        print(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        sys.exit(1)


def setup_environment(args, config):
    """è®¾ç½®è¿è¡Œç¯å¢ƒ"""
    # è®¾ç½®éšæœºç§å­
    import random
    import numpy as np
    random.seed(args.seed)
    np.random.seed(args.seed)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    os.makedirs("logs", exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—
    log_level = "DEBUG" if args.debug else ("INFO" if args.verbose else "WARNING")
    logger = setup_logger("toolace_generation", log_level)
    
    return logger


def run_tss_only(toolace, args, logger):
    """ä»…è¿è¡ŒTSSæ¨¡å—"""
    logger.info("ğŸ”§ è¿è¡ŒTSSæ¨¡å— (å·¥å…·è‡ªæ¼”åŒ–åˆæˆ)")
    
    start_time = time.time()
    api_pool = toolace.tss.run_synthesis(
        pretraining_data_path=toolace.config.get("tss", {}).get("pretraining_data_path"),
        target_api_count=args.api_count
    )
    
    # ä¿å­˜APIæ± 
    api_output_path = os.path.join(args.output_dir, "apis")
    os.makedirs(api_output_path, exist_ok=True)
    api_pool.export_apis(f"{api_output_path}/api_pool.json")
    
    elapsed = time.time() - start_time
    logger.info(f"âœ… TSSå®Œæˆ! ç”Ÿæˆ {len(api_pool.apis)} ä¸ªAPIï¼Œç”¨æ—¶ {elapsed:.2f}ç§’")
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    stats = api_pool.get_pool_statistics()
    logger.info(f"ğŸ“Š APIæ± ç»Ÿè®¡: {stats}")
    
    return {"api_count": len(api_pool.apis), "api_stats": stats}


def run_sdg_only(toolace, args, logger):
    """ä»…è¿è¡ŒSDGæ¨¡å—"""
    logger.info("ğŸ’¬ è¿è¡ŒSDGæ¨¡å— (è‡ªå¼•å¯¼å¯¹è¯ç”Ÿæˆ)")
    
    # éœ€è¦å…ˆåŠ è½½APIæ± 
    api_pool_path = os.path.join(args.output_dir, "apis/api_pool.json")
    if not os.path.exists(api_pool_path):
        logger.error("âŒ æœªæ‰¾åˆ°APIæ± æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡ŒTSSæ¨¡å—")
        return None
        
    # åŠ è½½APIæ±  (è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦å®ç°åŠ è½½é€»è¾‘)
    logger.info(f"ğŸ“¥ ä» {api_pool_path} åŠ è½½APIæ± ")
    
    start_time = time.time()
    dialogs = toolace.sdg.batch_generate_dialogs(
        api_pool=toolace.tss.api_pool,  # å®é™…åº”è¯¥ä»æ–‡ä»¶åŠ è½½
        count=args.dialog_count
    )
    
    # ä¿å­˜å¯¹è¯
    dialog_output_path = os.path.join(args.output_dir, "dialogs")
    os.makedirs(dialog_output_path, exist_ok=True)
    
    import json
    with open(f"{dialog_output_path}/dialogs.json", 'w', encoding='utf-8') as f:
        json.dump(dialogs, f, ensure_ascii=False, indent=2)
        
    elapsed = time.time() - start_time
    logger.info(f"âœ… SDGå®Œæˆ! ç”Ÿæˆ {len(dialogs)} ä¸ªå¯¹è¯ï¼Œç”¨æ—¶ {elapsed:.2f}ç§’")
    
    return {"dialog_count": len(dialogs)}


def run_dlv_only(toolace, args, logger):
    """ä»…è¿è¡ŒDLVæ¨¡å—"""
    logger.info("ğŸ” è¿è¡ŒDLVæ¨¡å— (åŒå±‚éªŒè¯)")
    
    # éœ€è¦å…ˆåŠ è½½å¯¹è¯æ•°æ®
    dialog_path = os.path.join(args.output_dir, "dialogs/dialogs.json")
    if not os.path.exists(dialog_path):
        logger.error("âŒ æœªæ‰¾åˆ°å¯¹è¯æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡ŒSDGæ¨¡å—")
        return None
        
    # åŠ è½½å¯¹è¯æ•°æ®
    import json
    logger.info(f"ğŸ“¥ ä» {dialog_path} åŠ è½½å¯¹è¯æ•°æ®")
    with open(dialog_path, 'r', encoding='utf-8') as f:
        dialogs = json.load(f)
        
    start_time = time.time()
    verification_results = toolace.dlv.batch_verify(dialogs)
    
    # ç­›é€‰éªŒè¯é€šè¿‡çš„å¯¹è¯
    valid_dialogs = [
        dialog for dialog, result in zip(dialogs, verification_results)
        if result["final_decision"] == "passed"
    ]
    
    # ä¿å­˜éªŒè¯é€šè¿‡çš„æ•°æ®
    verified_output_path = os.path.join(args.output_dir, "verified")
    os.makedirs(verified_output_path, exist_ok=True)
    
    with open(f"{verified_output_path}/verified_dialogs.json", 'w', encoding='utf-8') as f:
        json.dump(valid_dialogs, f, ensure_ascii=False, indent=2)
        
    # ä¿å­˜éªŒè¯æŠ¥å‘Š
    with open(f"{verified_output_path}/verification_report.json", 'w', encoding='utf-8') as f:
        json.dump(verification_results, f, ensure_ascii=False, indent=2)
        
    elapsed = time.time() - start_time
    pass_rate = len(valid_dialogs) / len(dialogs) if dialogs else 0
    logger.info(f"âœ… DLVå®Œæˆ! éªŒè¯é€šè¿‡ {len(valid_dialogs)}/{len(dialogs)} ä¸ªå¯¹è¯ ({pass_rate:.2%})ï¼Œç”¨æ—¶ {elapsed:.2f}ç§’")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = toolace.dlv.get_verification_statistics(verification_results)
    logger.info(f"ğŸ“Š éªŒè¯ç»Ÿè®¡: {stats}")
    
    return {
        "total_dialogs": len(dialogs),
        "valid_dialogs": len(valid_dialogs), 
        "pass_rate": pass_rate,
        "verification_stats": stats
    }


def run_full_pipeline(toolace, args, logger):
    """è¿è¡Œå®Œæ•´çš„ToolACEç®¡é“"""
    logger.info("ğŸš€ å¼€å§‹å®Œæ•´çš„ToolACEæ•°æ®ç”Ÿæˆç®¡é“")
    
    total_start_time = time.time()
    
    try:
        # è¿è¡Œå®Œæ•´ç®¡é“
        stats = toolace.generate_dataset(
            target_api_count=args.api_count,
            target_dialog_count=args.dialog_count
        )
        
        total_elapsed = time.time() - total_start_time
        
        logger.info("ğŸ‰ ToolACEç®¡é“æ‰§è¡Œå®Œæˆ!")
        logger.info(f"â±ï¸  æ€»ç”¨æ—¶: {total_elapsed:.2f}ç§’")
        logger.info(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡: {stats}")
        
        return stats
        
    except Exception as e:
        logger.error(f"âŒ ç®¡é“æ‰§è¡Œå¤±è´¥: {e}")
        if args.debug:
            import traceback
            traceback.print_exc()
        return None


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    
    # è®¾ç½®ç¯å¢ƒ
    logger = setup_environment(args, config)
    
    logger.info("ğŸ”§ åˆå§‹åŒ–ToolACE")
    logger.info(f"ğŸ“‹ é…ç½®æ–‡ä»¶: {args.config}")
    logger.info(f"ğŸ¯ ç›®æ ‡APIæ•°é‡: {args.api_count}")
    logger.info(f"ğŸ¯ ç›®æ ‡å¯¹è¯æ•°é‡: {args.dialog_count}")
    logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    
    # åˆå§‹åŒ–ToolACE
    try:
        # Initialize model manager first
        initialize_global_model_manager(args.config)
        logger.info("âœ… å…¨å±€æ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        toolace = ToolACE(config_path=args.config)
    except Exception as e:
        logger.error(f"âŒ ToolACEåˆå§‹åŒ–å¤±è´¥: {e}")
        sys.exit(1)
    
    # æ ¹æ®å‚æ•°è¿è¡Œç›¸åº”æ¨¡å—
    results = None
    
    if args.tss_only:
        results = run_tss_only(toolace, args, logger)
    elif args.sdg_only:
        results = run_sdg_only(toolace, args, logger)
    elif args.dlv_only or args.verify_only:
        results = run_dlv_only(toolace, args, logger)
    else:
        results = run_full_pipeline(toolace, args, logger)
    
    # ä¿å­˜æœ€ç»ˆç»“æœ
    if results:
        results_path = os.path.join(args.output_dir, "generation_results.json")
        import json
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ“„ ç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    
    logger.info("ğŸ ç¨‹åºæ‰§è¡Œå®Œæˆ")


if __name__ == "__main__":
    main()
