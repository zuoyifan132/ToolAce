#!/usr/bin/env python3
"""
ç®€å•çš„æ¨¡å‹è°ƒç”¨æµ‹è¯•è„šæœ¬

ç›´æ¥æµ‹è¯•ç®€åŒ–åçš„æ¨¡å‹è°ƒç”¨æ¥å£ï¼Œä¸ä¾èµ–é¡¹ç›®çš„å…¶ä»–å¤æ‚æ¨¡å—
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__)))

def test_simple_model_calls():
    """æµ‹è¯•ç®€åŒ–çš„æ¨¡å‹è°ƒç”¨"""
    print("ğŸš€ æµ‹è¯•ç®€åŒ–çš„æ¨¡å‹è°ƒç”¨æ¥å£")
    
    # æµ‹è¯•1: ç›´æ¥ä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨
    print("\nğŸ“Š æµ‹è¯•1: ä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨")
    try:
        from toolace.utils.model_manager import get_model_generator, generate, stream_generate
        
        # è·å–Mockæ¨¡å‹ç”Ÿæˆå™¨
        print("\nğŸ­ è·å–Mockæ¨¡å‹ç”Ÿæˆå™¨:")
        mock_generator = get_model_generator("mock_llm")
        response = mock_generator(
            "ä½ æ˜¯ä¸€ä¸ªAPIè®¾è®¡ä¸“å®¶ã€‚", 
            "è¯·è®¾è®¡ä¸€ä¸ªå¤©æ°”æŸ¥è¯¢API", 
            temperature=0.7
        )
        print(f"âœ… Mockæ¨¡å‹å“åº”: {response[:100]}...")
        
        # ä½¿ç”¨ç»Ÿä¸€ç”Ÿæˆå‡½æ•°
        print("\nğŸ”§ ä½¿ç”¨ç»Ÿä¸€ç”Ÿæˆå‡½æ•°:")
        response2 = generate(
            model_key="mock_llm",
            system_prompt="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚",
            user_prompt="è¯·é—®ä»€ä¹ˆæ˜¯å‡½æ•°è°ƒç”¨ï¼Ÿ",
            temperature=0.5
        )
        print(f"âœ… ç»Ÿä¸€æ¥å£å“åº”: {response2[:100]}...")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•2: ç›´æ¥å¯¼å…¥æ¨¡å‹æ¨¡å—
    print("\nğŸ“Š æµ‹è¯•2: ç›´æ¥å¯¼å…¥æ¨¡å‹æ¨¡å—")
    try:
        from toolace.utils.model_generator import mock_llm
        print("\nğŸ¯ ç›´æ¥ä½¿ç”¨mock_llmæ¨¡å—:")
        response3 = mock_llm.generate(
            system="ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹åŠ©æ‰‹ã€‚",
            user="è§£é‡Šä»€ä¹ˆæ˜¯API",
            temperature=0.8
        )
        print(f"âœ… ç›´æ¥å¯¼å…¥å“åº”: {response3[:100]}...")
        
    except Exception as e:
        print(f"âŒ ç›´æ¥å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•3: æµå¼ç”Ÿæˆ
    print("\nğŸ“Š æµ‹è¯•3: æµå¼ç”Ÿæˆ")
    try:
        print("\nğŸŒŠ æµå¼ç”Ÿæˆæµ‹è¯•:")
        chunks = list(stream_generate(
            model_key="mock_llm",
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæ•…äº‹è®²è¿°è€…ã€‚",
            user_prompt="è®²ä¸€ä¸ªç®€çŸ­çš„æ•…äº‹",
            temperature=0.9
        ))
        print(f"âœ… æµå¼ç”Ÿæˆå®Œæˆï¼Œå…± {len(chunks)} ä¸ªç‰‡æ®µ")
        
    except Exception as e:
        print(f"âŒ æµå¼ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•4: Qwenæ¨¡å‹ï¼ˆå¦‚æœç½‘ç»œå¯ç”¨ï¼‰
    print("\nğŸ“Š æµ‹è¯•4: Qwenæ¨¡å‹è°ƒç”¨")
    try:
        print("\nğŸ¤– å°è¯•è°ƒç”¨Qwenæ¨¡å‹:")
        qwen_generator = get_model_generator("qwen3_32b")
        # è¿™é‡Œå¯èƒ½ä¼šå› ä¸ºç½‘ç»œé—®é¢˜å¤±è´¥ï¼Œä½†è‡³å°‘å¯ä»¥æµ‹è¯•å¯¼å…¥
        print("âœ… Qwenæ¨¡å‹ç”Ÿæˆå™¨è·å–æˆåŠŸï¼ˆæœªå®é™…è°ƒç”¨APIï¼‰")
        
    except Exception as e:
        print(f"âš ï¸ Qwenæ¨¡å‹æµ‹è¯•: {e}")
    
    print("\nğŸ‰ ç®€åŒ–æ¨¡å‹è°ƒç”¨æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ æ€»ç»“:")
    print("1. âœ… æ–°çš„æ¨¡å‹ç®¡ç†å™¨å·¥ä½œæ­£å¸¸")
    print("2. âœ… get_model_generator() å‡½æ•°å·¥ä½œæ­£å¸¸")
    print("3. âœ… generate() ç»Ÿä¸€æ¥å£å·¥ä½œæ­£å¸¸")
    print("4. âœ… ç›´æ¥å¯¼å…¥æ¨¡å‹æ¨¡å—å·¥ä½œæ­£å¸¸")
    print("5. âœ… æµå¼ç”Ÿæˆæ¥å£å·¥ä½œæ­£å¸¸")
    print("\nğŸ”§ æ–°çš„è°ƒç”¨æ–¹å¼:")
    print("   - get_model_generator('model_name') è·å–ç”Ÿæˆå‡½æ•°")
    print("   - generate(model_key, system_prompt, user_prompt, **kwargs)")
    print("   - ç›´æ¥å¯¼å…¥: from toolace.utils.model_generator import mock_llm")


if __name__ == "__main__":
    test_simple_model_calls()
